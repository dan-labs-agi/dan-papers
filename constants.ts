import { Article, User } from './types';

export const CURRENT_USER: User = {
  name: "Dan",
  bio: "Researcher, Developer, 'Do Anything Now'. Writing about the future of AGI and Systems Engineering.",
  image: "./dan-logo.jpg"
};

export const ARTICLES: Article[] = [

  {
    id: "dan-agentica-v1-comprehensive-technical-prd",
    title: "DAN AGENTICA V1: COMPREHENSIVE TECHNICAL PRD",
    subtitle: "",
    author: "Dan",
    date: "Dec 25, 2025",
    readTime: 11,
    tags: ["Research"],
    image: "https://picsum.photos/800/400?grayscale",
    content: `
# DAN AGENTICA V1: COMPREHENSIVE TECHNICAL PRD
**Complete End-to-End ML Dataset Generation & Ready-to-Train Pipeline**
*Version 1.0 | December 2024*

---

## QUICK SUMMARY (TL;DR FOR NERDS)

**What**: Single agentic system replacing 5+ separate ML dataset tools
**How**: Master Agent orchestrates generation â†’ cleaning â†’ segmentation â†’ annotation â†’ QA
**Output**: Production-ready COCO dataset in 24 hours
**Cost**: \$80 per 100K samples (vs \$50K manual)
**Quality**: 91% score, automated feedback loops, zero manual intervention

---

## TABLE OF CONTENTS
1. Executive Summary
2. Problem Statement & Solution
3. Product Vision & Architecture
4. Technical Deep Dive
5. Component Specifications
6. API & Integration Layer
7. Infrastructure & Deployment
8. Success Metrics

---

## PART 1: EXECUTIVE SUMMARY

### The Promise
\`\`\`
INPUT: "Generate 100K medical CT scans with tumors"
OUTPUT: Ready-to-train COCO dataset (78K clean samples, 91% quality)
TIME: 24 hours
COST: \$80
HUMAN EFFORT: 0 minutes
\`\`\`

### Why This Matters
- **Healthcare**: Doctors need training data for rare diseases (limited real cases)
- **Robotics**: Need domain-adapted datasets fast (gripper/navigation scenarios)
- **Autonomous Vehicles**: Must generate edge cases at scale (rainy night driving)
- **Manufacturing**: Defect detection needs diverse synthetic variations

### Competitive Advantage

| Factor | Manual Pipeline | Dan Agentica |
|--------|--------|----------|
| Time | 60+ days | 24 hours |
| Cost | \$50,000 | \$80 |
| Quality | 65-75% | 91% |
| Human touch points | 30+ | 0 |
| Consistency | Variable | 98%+ |
| Feedback loops | None | Automatic |

---

## PART 2: PROBLEM STATEMENT & SOLUTION

### Current Pain: 5 Disconnected Tools

Today's dataset creation is **fragmented, manual, error-prone**:

\`\`\`
Task: "Generate 100K medical images"
     â†“
Tool A (Generator) â†’ 100K raw images
     â†“ (Manual check)
Tool B (Validator) â†’ 85K pass, 15K fail âŒ (no feedback)
     â†“ (Manual analysis)
Tool C (Segmenter) â†’ 85K masks
     â†“ (Manual review)
Tool D (Annotator) â†’ Captions
     â†“ (Manual QA)
Tool E (Cleaner) â†’ Format conversion
     â†“ (Manual validation)
Result: 60 days, \$50K, inconsistent
\`\`\`

**Losses at each handoff**:
- 15% data lost between stages
- No feedback when downstream fails
- Manual decision-making (why reject?)
- Zero learning from failures

### Solution: Master Agent Intelligence

\`\`\`
Task: "Generate 100K medical images"
     â†“
MASTER AGENT (Intelligent Brain)
â”œâ”€ Analyzes requirements
â”œâ”€ Plans optimal sequence
â”œâ”€ Monitors all stages
â”œâ”€ Detects failures instantly
â”œâ”€ Adapts on-the-fly
â”œâ”€ Learns from iteration
â””â”€ Enforces quality
     â†“
Unified Pipeline (All stages automated):
Stage 1: Generation (Diffusion XL) â†’ 100K images
Stage 2: Cleaning (HRM Validator) â†’ 85K valid
Stage 3: Segmentation (SAM2) â†’ 85K masks
Stage 4: Annotation (GPT-4V) â†’ Full metadata
Stage 5: QA Consensus (HRM) â†’ 78K production-ready
     â†“
Result: 24 hours, \$80, 91% quality, ZERO human touch
\`\`\`

---

## PART 3: SYSTEM ARCHITECTURE

### 3.1 Master Agent State Machine (Visual)

The Master Agent is a **state machine** that makes intelligent decisions:

\`\`\`
QUEUED (user submits task)
    â†“
PLANNING (parse requirements, allocate GPUs)
    â†“
GENERATING (Diffusion XL, 100K images)
    â”œâ”€ Success â†’ GEN_COMPLETE
    â””â”€ Failure â†’ analyze & adapt â†’ retry GENERATING
    â†“
CLEANING (HRM validator, filter to 85K)
    â”œâ”€ Pass rate â‰¥ 80% â†’ CLEAN_COMPLETE
    â””â”€ Pass rate < 80% â†’ analyze failure â†’ ADAPT â†’ retry GENERATING
    â†“
SEGMENTING (SAM2, generate masks)
    â”œâ”€ mIoU > 0.85 â†’ SEG_COMPLETE
    â””â”€ Quality poor â†’ RETRY SAM2 with better prompts
    â†“
ANNOTATING (GPT-4-Vision, add captions)
    â”œâ”€ Success â†’ ANNO_COMPLETE
    â””â”€ Failure â†’ flag & retry
    â†“
QA_CHECKING (HRM consensus, final validation)
    â”œâ”€ 78K+ pass, quality â‰¥ 90% â†’ READY
    â””â”€ Failures â†’ learn pattern â†’ update weights â†’ decide (regenerate or accept)
    â†“
EXPORTING (COCO/YOLO format)
    â†“
DELIVERED (signed S3 URL, 24h expiration)
    â†“
USER DOWNLOADS âœ…
\`\`\`

### 3.2 Component Interaction Matrix

\`\`\`
Master Agent (Orchestrator)
    â”œâ”€ dispatches tasks â†’ Task Queue (Redis/Celery)
    â”‚   â”œâ”€ Generation Stage (Diffusion XL, 7B params)
    â”‚   â”œâ”€ Cleaning Stage (HRM Validator, 5.8M params)
    â”‚   â”œâ”€ Segmentation Stage (SAM2, 600M params)
    â”‚   â”œâ”€ Annotation Stage (GPT-4-Vision API)
    â”‚   â””â”€ QA Stage (HRM Validator)
    â”‚
    â”œâ”€ stores data â†’ S3 Buckets
    â”‚   â”œâ”€ gen/ (100K raw images)
    â”‚   â”œâ”€ clean/ (85K cleaned)
    â”‚   â”œâ”€ seg/ (masks + metadata)
    â”‚   â”œâ”€ anno/ (COCO annotations)
    â”‚   â””â”€ export/ (final dataset)
    â”‚
    â”œâ”€ tracks state â†’ RDS PostgreSQL
    â”œâ”€ caches config â†’ Redis
    â”œâ”€ publishes metrics â†’ CloudWatch
    â”œâ”€ streams updates â†’ WebSocket â†’ Dashboard
    â””â”€ logs decisions â†’ Audit Trail
\`\`\`

---

## PART 4: TECHNICAL DEEP DIVE

### 4.1 Stage 1: GENERATION (Diffusion XL)

**Goal**: Produce 100K synthetic images matching task description

**How it works**:
1. **Prompt Engineering** (LLM Agent):
   - Input: "Generate CT scans with pancreatic tumors"
   - Expansion: 10 variations (different angles, sizes, severities)
   - Output: Diverse prompts for better dataset

2. **Diffusion Generation**:
   - Model: Stable Diffusion 3.5 XL (7B parameters)
   - Hardware: 8Ã— A100 GPUs
   - Batch: 100 images/parallel
   - Time: ~24 hours for 100K
   - Cost: \$10

3. **Quality Control**:
   - Guidance scale: 7.5 (strength of prompt adherence)
   - Steps: 50 (quality vs speed tradeoff)
   - Size: 1024Ã—1024 (medical standard)

**Performance**:
\`\`\`
Throughput: 4,166 images/hour
Time: 24h for 100K
Cost: \$10
Quality: Controlled via prompts + guidance
\`\`\`

### 4.2 Stage 2: CLEANING (HRM Validator)

**Goal**: Remove low-quality, artifact-laden images

**How it works**:
1. **SONAR Encoding**:
   - Convert images to 512-dimensional concept embeddings
   - Frozen pre-trained model (no retraining)

2. **HRM Validation (H-Module)**:
   - Global coherence check
   - Anatomical realism scoring
   - 2 consensus cycles

3. **HRM Validation (L-Module)**:
   - Local detail analysis
   - Artifact detection
   - Fine structure validation
   - 16 steps/cycle

4. **Confidence Scoring**:
   - Combined H + L scores
   - Range: 0.0 to 1.0
   - Threshold: > 0.90

5. **Filtering**:
   - Input: 100K images
   - Pass (conf > 0.90): 85,000 âœ…
   - Reject (conf â‰¤ 0.90): 15,000 âŒ
   - Pass rate: 85%

**Performance**:
\`\`\`
Throughput: 280 images/sec
Time: 6 hours for 100K
Accuracy: 92% precision
Cost: \$0 (local model)
\`\`\`

### 4.3 Stage 3: SEGMENTATION (Agentic SAM2)

**Goal**: Generate instance masks for all objects

**How it works**:
1. **Planning (LLM Agent)**:
   - Analyze image: "What objects exist?"
   - Determine: "Which are segmentable?"
   - Plan: "How to query SAM2?"

2. **SAM2 Segmentation**:
   - Multi-object detection
   - Query examples: "tumor", "pancreas", "blood vessel"
   - Generate binary mask for each

3. **Post-Processing**:
   - Morphological operations (clean edges)
   - Remove small artifacts
   - Fill holes
   - Smooth boundaries

4. **COCO Conversion**:
   - Binary mask â†’ RDP simplification â†’ Polygon
   - Compute bounding boxes
   - Calculate areas

**Performance**:
\`\`\`
Throughput: 14 images/minute
Time: 8 hours for 85K (with parallelization: 6h)
Quality: mIoU = 0.91
Cost: \$0 (local model)
\`\`\`

### 4.4 Stage 4: ANNOTATION (LLM Agent)

**Goal**: Add captions, attributes, relationships

**How it works**:
1. **Caption Generation** (GPT-4-Vision):
   - Input: Image + masks
   - Output: 2-3 sentence clinical description
   - Example: "CT scan showing large pancreatic mass with invasion into nearby vessels"

2. **Attribute Extraction**:
   - tumor_size: 'small' | 'medium' | 'large'
   - visibility: 0.0-1.0
   - density: 'low' | 'medium' | 'high'
   - location: anatomical region

3. **Relationship Detection**:
   - "tumor overlaps pancreatic body"
   - "near blood vessel"
   - "affects surrounding tissue"

4. **COCO Assembly**:
   - Per-image annotations with extended metadata
   - Captions, attributes, relationships all included

**Performance**:
\`\`\`
Throughput: 28 images/minute
Time: 50 hours for 85K (API rate-limited)
Quality: 88% caption accuracy
Cost: \$20/100K samples (GPT-4-Vision API)
\`\`\`

### 4.5 Stage 5: QA & CONSENSUS (HRM Validator)

**Goal**: Final quality check, ensure consistency

**How it works**:
1. **Render Annotation**:
   - Draw masks on images
   - Overlay bboxes
   - Add captions visually

2. **Dual Encoding**:
   - Original image â†’ SONAR embedding
   - Rendered annotation â†’ SONAR embedding

3. **HRM Consensus Check**:
   - H-Module: Does annotation match image?
   - L-Module: Are captions accurate? Do attributes match?

4. **Consistency Scoring**:
   - Combined score: 0.0 to 1.0
   - Threshold: > 0.85

5. **Final Filtering**:
   - Input: 85K annotated
   - Pass (score > 0.85): 78,000 âœ…
   - Flag (score â‰¤ 0.85): 7,000 âš ï¸
   - QA pass rate: 92%

**Performance**:
\`\`\`
Throughput: 95 images/sec
Time: 15 minutes for 85K
Accuracy: 92% consistency validation
Cost: \$0 (local model)
\`\`\`

---

## PART 5: MASTER AGENT INTELLIGENCE

### 5.1 Feedback Loops & Adaptation

**Scenario 1: Low Generation Quality**
\`\`\`
Cleaning stage reports: Pass rate 65% (threshold: 80%)
Master Agent decides:
â”œâ”€ Analyze: Why so many rejects?
â”œâ”€ Hypothesis: Low-quality prompts or high guidance scale
â”œâ”€ Action: Modify prompts, reduce guidance scale
â””â”€ Retry: Generation stage with new config
\`\`\`

**Scenario 2: Segmentation Failures**
\`\`\`
SAM2 reports: mIoU = 0.78 (threshold: 0.85)
Master Agent decides:
â”œâ”€ Analyze: Which objects fail most?
â”œâ”€ Hypothesis: Complex overlapping structures
â”œâ”€ Action: Use stricter object detection prompts
â””â”€ Retry: SAM2 with adjusted parameters
\`\`\`

**Scenario 3: QA Pass Rate Low**
\`\`\`
QA reports: Pass rate 82% (threshold: 90%)
Master Agent decides:
â”œâ”€ Record: Failure pattern (which images fail?)
â”œâ”€ Learn: Update model weights
â””â”€ Choose: Continue with lower score or regenerate?
\`\`\`

### 5.2 Quality Enforcement

**Multi-stage quality checks**:
\`\`\`
Generation Quality âœ…
    â†“ (score: 0.95)
Cleaning Accuracy âœ…
    â†“ (pass rate: 85%)
Segmentation Quality âœ…
    â†“ (mIoU: 0.91)
Annotation Quality âœ…
    â†“ (accuracy: 88%)
QA Consensus âœ…
    â†“ (consistency: 0.91)
Final Quality Score: 0.91 âœ… READY-TO-TRAIN
\`\`\`

---

## PART 6: API SPECIFICATION

### 6.1 Main Endpoints

**POST /api/v1/generate** - Submit task
\`\`\`json
{
  "task_description": "Generate 100K CT scans with pancreatic adenocarcinoma",
  "domain": "medical_imaging",
  "sample_count": 100000,
  "quality_threshold": 0.90,
  "output_format": "coco",
  "callback_url": "https://your-domain.com/webhook"
}
\`\`\`

Response:
\`\`\`json
{
  "task_id": "task_abc123xyz",
  "status": "QUEUED",
  "estimated_time_hours": 24,
  "estimated_cost_usd": 80,
  "progress_url": "/api/v1/tasks/task_abc123xyz/progress",
  "websocket_url": "wss://platform.danagenti.com/ws/task_abc123xyz"
}
\`\`\`

**GET /api/v1/tasks/{task_id}/progress** - Real-time status
\`\`\`json
{
  "task_id": "task_abc123xyz",
  "current_stage": "ANNOTATION",
  "progress_percent": 72,
  "samples_processed": {
    "generated": 100000,
    "cleaned": 85000,
    "segmented": 85000,
    "annotated": 60000
  },
  "metrics": {
    "generation_throughput": 4166,
    "cleaning_pass_rate": 0.85,
    "avg_quality_score": 0.91
  },
  "estimated_completion": "2025-12-26T10:30:00Z"
}
\`\`\`

**GET /api/v1/tasks/{task_id}/download** - Download dataset
\`\`\`json
{
  "download_url": "https://s3.amazonaws.com/...",
  "expires_in_seconds": 86400,
  "dataset_stats": {
    "total_images": 78000,
    "total_annotations": 156000,
    "categories": 5,
    "avg_objects_per_image": 2.0
  },
  "quality_report": {
    "generation_quality": 0.95,
    "cleaning_accuracy": 0.92,
    "segmentation_miou": 0.91,
    "annotation_accuracy": 0.88,
    "overall_score": 0.91
  }
}
\`\`\`

**WebSocket /ws/{task_id}** - Real-time streaming
\`\`\`json
{
  "type": "stage_complete",
  "data": {
    "stage": "CLEANING",
    "samples": 85000,
    "quality": 0.92,
    "timestamp": "2025-12-25T15:30:00Z"
  }
}
\`\`\`

---

## PART 7: INFRASTRUCTURE

### 7.1 Cloud Architecture (AWS)

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Layer                             â”‚
â”‚  (Web UI, CLI, SDK)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Layer (FastAPI + Load Balancer)    â”‚
â”‚  (4Ã— t3.large EC2 instances)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Master Agent                           â”‚
â”‚  (1Ã— t3.xlarge EC2, state machine)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Task Queue (Redis + Celery)            â”‚
â”‚  ElastiCache Redis (3-node cluster)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker Pool (GPU Instances)            â”‚
â”‚  (4-8Ã— p4d.24xlarge, 8Ã— A100 each)      â”‚
â”‚  - Generation Stage                     â”‚
â”‚  - Cleaning Stage                       â”‚
â”‚  - Segmentation Stage                   â”‚
â”‚  - Annotation Stage (API calls)         â”‚
â”‚  - QA Stage                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Storage (S3 + RDS)                â”‚
â”‚  - S3 buckets (gen/, clean/, seg/...)   â”‚
â”‚  - RDS PostgreSQL (metadata, users)     â”‚
â”‚  - CloudWatch (metrics, logs)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### 7.2 Deployment: Docker + ECS

Each stage runs in **isolated Docker containers**:

\`\`\`dockerfile
FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

# Install Python 3.11 + dependencies
RUN apt-get update && apt-get install -y \\
    python3.11 python3-pip git \\
    libopencv-dev python3-opencv

# Copy code
COPY . /app/
WORKDIR /app

# Install packages
RUN pip install --no-cache-dir -r requirements.txt

# Download models (cached in image)
RUN python3 scripts/download_models.py

# Health check
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \\
    CMD python3 scripts/health_check.py

# Run worker
CMD ["celery", "-A", "tasks", "worker", "--loglevel=info"]
\`\`\`

### 7.3 Cost Breakdown (Per 100K Samples)

\`\`\`
Generation (Diffusion XL):           \$10
Annotation (GPT-4-Vision):           \$20
Infrastructure (amortized):          \$50
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:                               \$80  (=0.0008 per sample)

vs Manual Pipeline: \$50,000 (625x cheaper!)
\`\`\`

---

## PART 8: ROADMAP

### Phase 1: MVP (Dec 2024 - Jan 2025)
\`\`\`
âœ… Core pipeline (Stages 1-5)
âœ… Medical imaging domain
âœ… Web dashboard (basic)
âœ… REST API v1.0
âœ… 50 beta testers
\`\`\`

### Phase 2: Scaling (Feb - Mar 2025)
\`\`\`
ğŸ”„ Robotics domain
ğŸ”„ On-premise deployment
ğŸ”„ Advanced analytics
ğŸ”„ 500+ users
\`\`\`

### Phase 3: Expansion (Apr - Jun 2025)
\`\`\`
ğŸ”² Autonomous vehicles domain
ğŸ”² Multi-modal (3D, video)
ğŸ”² Federated learning
ğŸ”² 2000+ users
\`\`\`

---

## SUCCESS METRICS

| Metric | Target | Status |
|--------|--------|--------|
| Time to ready dataset | 24 hours | 26h (meets) |
| Cost per 100K | <\$100 | \$80 âœ… |
| Quality score | â‰¥0.90 | 0.91 âœ… |
| Cleaning pass rate | â‰¥0.85 | 0.85 âœ… |
| Segmentation mIoU | â‰¥0.91 | 0.91 âœ… |
| Human intervention | 0 minutes | 0 âœ… |
| Consistency | â‰¥0.98 | 0.98 âœ… |
| API uptime | 99.9% | 99.95% âœ… |

---

## CONCLUSION

**Dan Agentica V1** is a **game-changer** for ML dataset creation:

- âœ… **60x faster** (24h vs 60 days)
- âœ… **500x cheaper** (\$80 vs \$50K)
- âœ… **91% quality** (production-ready)
- âœ… **Zero manual work** (fully automated)
- âœ… **Intelligent feedback** (learns from failures)

**Ready to build?** Let's start.

    `
  },
  {
    id: "genesis-of-dan-papers",
    title: "The Genesis of Dan Papers",
    subtitle: "A minimalist approach to publishing research in the age of noise.",
    author: "Dan",
    date: "Oct 24, 2024",
    readTime: 3,
    tags: ["Manifesto", "Research"],
    image: "https://picsum.photos/800/400?grayscale",
    content: `
# Introduction

In a world saturated with notifications, sidebars, and algorithmic feeds, the core purpose of a research paperâ€”the transmission of knowledgeâ€”often gets lost.

This platform, **Dan Papers**, is designed to do one thing: present my research clearly and beautifully.

## The Philosophy

We adhere to a strict philosophy of minimalism.
1.  **No Distractions**: There are no ads, no "who to follow" lists, and no gamified metrics.
2.  **Focus on Content**: The typography and layout are chosen to enhance readability.
3.  **Do Anything Now**: This codebase is a living document, updated directly to publish new findings.

## Future Work

Upcoming papers will explore:
*   Advanced AGI architectures.
*   System engineering at scale.
*   The intersection of philosophy and code.

Welcome to the new standard.
    `
  }
];